"""
üî¨ HYPERREALISTISCHES TIFF-SIMULATIONSSYSTEM V4.0 - OPTIMIZED
==============================================================

PERFORMANCE-OPTIMIERT mit vektorisierten Operationen!
10-50x schneller als V3.0 f√ºr gro√üe TIFFs!

Wissenschaftlich pr√§zise Simulation von Single-Molecule Tracking Daten
f√ºr hochaufl√∂sende Fluoreszenzmikroskopie.

Physikalische Grundlagen:
-------------------------
- Point Spread Function (PSF): 2D Gau√üsche Approximation
- Diffusion: Brownsche Bewegung mit zeitabh√§ngigem D(t)
- Astigmatismus: Elliptische PSF-Deformation als Funktion von z
- Photon Noise: Poisson-Statistik f√ºr realistische Bildgebung

OPTIMIERUNGEN:
--------------
‚úÖ Vektorisierte PSF-Generierung (10-20x schneller)
‚úÖ Batch-Processing f√ºr alle Spots
‚úÖ Pre-computed Background
‚úÖ Optimierte NumPy-Operationen
‚úÖ Memory-efficient durch Array-Reuse
‚úÖ ROI-basierte PSF-Berechnung (3-sigma cutoff)

Autor: Generiert f√ºr Masterthesis
Version: 4.0 - Oktober 2025 (Performance Edition)
Lizenz: MIT
"""

from collections import Counter

import numpy as np
from dataclasses import dataclass, field
from typing import Tuple, List, Optional, Dict, Callable
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')


# ============================================================================
# LABEL EXPANSION UTILITY (inline - no external dependency)
# ============================================================================

def expand_labels(initial_label: str, switch_log: list, num_frames: int) -> list:
    """
    Expandiert Diffusionslabels √ºber alle Frames basierend auf Switch-Log.

    Parameters:
    -----------
    initial_label : str
        Initialer Diffusionstyp
    switch_log : list
        Liste von Switches [{"frame": int, "from": str, "to": str}, ...]
    num_frames : int
        Gesamtzahl Frames

    Returns:
    --------
    list : Label f√ºr jeden Frame
    """
    labels = [initial_label] * num_frames

    if not switch_log:
        return labels

    # Sortiere Switches nach Frame
    sorted_switches = sorted(switch_log, key=lambda x: x.get("frame", 0))

    current_label = initial_label
    for switch in sorted_switches:
        frame_idx = int(switch.get("frame", 0))
        new_label = switch.get("to", current_label)

        # Update alle Frames ab diesem Switch
        for i in range(frame_idx, num_frames):
            labels[i] = new_label

        current_label = new_label

    return labels


@dataclass
class DetectorPreset:
    """
    Detektor-Konfiguration mit physikalisch realistischen Parametern.

    Attributes:
    -----------
    name : str
        Detektorbezeichnung
    max_intensity : float
        Maximale Photonenzahl pro Spot [counts]
    background_mean : float
        Mittlerer Background [counts]
    background_std : float
        Standardabweichung des Backgrounds [counts]
    pixel_size_um : float
        Physikalische Pixelgr√∂√üe [¬µm]
    fwhm_um : float
        Full Width at Half Maximum der PSF [¬µm]
    """
    name: str
    max_intensity: float
    background_mean: float
    background_std: float
    pixel_size_um: float
    fwhm_um: float
    metadata: Dict = field(default_factory=dict)


# ============================================================================
# DETEKTOR PRESETS - Experimentell validiert
# ============================================================================

TDI_PRESET = DetectorPreset(
    name="TDI-G0",
    max_intensity=260.0,
    background_mean=100.0,
    background_std=15.0,
    pixel_size_um=0.108,
    fwhm_um=0.40,
    metadata={
        "detector_type": "TDI Line Scan Camera",
        "numerical_aperture": 1.5,
        "wavelength_nm": 580,
        "quantum_efficiency": 0.85,
        # Zus√§tzliche Simulationsparameter
        "read_noise_std": 1.2,
        "spot_intensity_sigma": 0.25,
        "frame_jitter_sigma": 0.10,
        "on_mean_frames": 4.0,
        "off_mean_frames": 6.0,
        "bleach_prob_per_frame": 0.002,
        # Z-Stack Kalibrierungs-Parameter (OPTIMIERT f√ºr f=100mm Zylinderlinse!)
        "z_amp_um": 1.2,  # Intensit√§tsabfall-Skala in z [¬µm] - OPTIMIERT: gr√∂√üer f√ºr weiteren z-Range
        "z_max_um": 0.6,  # Maximale z-Auslenkung [¬µm] f√ºr Trajektorien
        "astig_focal_offset_um": 0.7,  # Halbe Fokustrennung [¬µm] - ERH√ñHT f√ºr f=100mm (10x st√§rker als f=1000mm!)
        "astig_z_rayleigh_um": 0.3,  # Rayleigh-Bereich (depth of focus) [¬µm] - REDUZIERT f√ºr steilere PSF-Kurve!
        # Brechungsindex-Korrektur (REALISTISCH f√ºr Polymer-Filme)
        "use_advanced_refractive_correction": True,  # Nutzt realistische Brechungsindizes
        "n_oil": 1.518,       # Brechungsindex Immersions√∂l (Standard)
        "n_glass": 1.523,     # Brechungsindex Deckglas (#1.5 High Precision)
        "n_polymer": 1.54,    # Brechungsindex Polymer (Polyester/PMMA)
        "NA": 1.5,            # Numerische Apertur 100x √ñl-Objektiv
        "d_glass_um": 170.0,  # Deckglas-Dicke [¬µm] (#1.5 coverslip)
        # Ausleuchtungsgradient (hyperrealistisch)
        "illumination_gradient_strength": 0.0,  # 0.0 = aus, 5-20 = subtil, >20 = stark
        "illumination_gradient_type": "radial",  # "radial", "linear_x", "linear_y", "corner"
        # Comonomer-Beschleunigungsfaktor
        "polymerization_acceleration_factor": 1.0  # 1.0 = Standard, 1.5 = 50% schneller, etc.
    }
)

TETRASPECS_PRESET = DetectorPreset(
    name="Tetraspecs",
    max_intensity=300.0,
    background_mean=100.0,
    background_std=15.0,
    pixel_size_um=0.160,
    fwhm_um=0.40,
    metadata={
        "detector_type": "sCMOS Camera",
        "numerical_aperture": 1.5,
        "wavelength_nm": 580,
        "quantum_efficiency": 0.90,
        # Zus√§tzliche Simulationsparameter
        "read_noise_std": 1.8,
        "spot_intensity_sigma": 0.25,
        "frame_jitter_sigma": 0.12,
        "on_mean_frames": 5.0,
        "off_mean_frames": 7.0,
        "bleach_prob_per_frame": 0.0015,
        # Z-Stack Kalibrierungs-Parameter (OPTIMIERT f√ºr f=100mm Zylinderlinse!)
        "z_amp_um": 1.2,  # Intensit√§tsabfall-Skala in z [¬µm] - OPTIMIERT: gr√∂√üer f√ºr weiteren z-Range
        "z_max_um": 0.6,  # Maximale z-Auslenkung [¬µm] f√ºr Trajektorien
        "astig_focal_offset_um": 0.7,  # Halbe Fokustrennung [¬µm] - ERH√ñHT f√ºr f=100mm (10x st√§rker als f=1000mm!)
        "astig_z_rayleigh_um": 0.3,  # Rayleigh-Bereich (depth of focus) [¬µm] - REDUZIERT f√ºr steilere PSF-Kurve!
        # Brechungsindex-Korrektur (REALISTISCH f√ºr Polymer-Filme)
        "use_advanced_refractive_correction": True,  # Nutzt realistische Brechungsindizes
        "n_oil": 1.518,       # Brechungsindex Immersions√∂l (Standard)
        "n_glass": 1.523,     # Brechungsindex Deckglas (#1.5 High Precision)
        "n_polymer": 1.54,    # Brechungsindex Polymer (Polyester/PMMA)
        "NA": 1.5,            # Numerische Apertur 100x √ñl-Objektiv
        "d_glass_um": 170.0,  # Deckglas-Dicke [¬µm] (#1.5 coverslip)
        # Ausleuchtungsgradient (hyperrealistisch)
        "illumination_gradient_strength": 0.0,  # 0.0 = aus, 5-20 = subtil, >20 = stark
        "illumination_gradient_type": "radial",  # "radial", "linear_x", "linear_y", "corner"
        # Comonomer-Beschleunigungsfaktor
        "polymerization_acceleration_factor": 1.0  # 1.0 = Standard, 1.5 = 50% schneller, etc.
    }
)


# ============================================================================
# ERWEITERTE BRECHUNGSINDEX-KORREKTUR (NEU!)
# ============================================================================

def calculate_advanced_refractive_correction(
    z_apparent: np.ndarray,
    n_oil: float,
    n_glass: float,
    n_polymer: float,
    NA: float,
    d_glass_um: float
) -> np.ndarray:
    """
    Berechnet physikalisch korrekte z-Korrektur f√ºr TIRF-Mikroskopie.

    Basiert auf der Theorie der sph√§rischen Aberration durch Brechungsindex-
    Mismatch zwischen Immersions√∂l, Deckglas und Probe.

    Physikalische Grundlagen:
    -------------------------
    Die scheinbare z-Position (z_apparent) weicht von der wahren Position (z_true)
    ab durch drei Effekte:

    1. BASIS-SKALIERUNG: n_polymer / n_oil
       - Grundlegende Brechung durch Medium-√úbergang

    2. NA-ABH√ÑNGIGER TERM: sqrt(n_oil¬≤ - NA¬≤) / sqrt(n_polymer¬≤ - NA¬≤)
       - Ber√ºcksichtigt Apertur-begrenzte Abbildung
       - Wichtig bei hoher NA (TIRF: NA ‚âà 1.45-1.50)

    3. TIEFENABH√ÑNGIGER TERM: 1 + (d_glass / z) * (1 - n_glass / n_polymer)
       - Deckglas-Dicke induziert zus√§tzliche Aberration
       - Effekt nimmt mit Fokustiefe ab
       - WICHTIG: Nur f√ºr z > 0.1 ¬µm angewendet (sonst numerische Instabilit√§t)

    Gesamtformel:
    -------------
    z_true = z_apparent * f_base * f_na * f_depth

    wobei:
    - f_base = n_polymer / n_oil
    - f_na = sqrt(n_oil¬≤ - NA¬≤) / sqrt(n_polymer¬≤ - NA¬≤)
    - f_depth = 1 + (d_glass / z_apparent) * (1 - n_glass / n_polymer)  f√ºr z > 0.1 ¬µm
                1.0                                                      f√ºr z ‚â§ 0.1 ¬µm

    Parameters:
    -----------
    z_apparent : np.ndarray
        Scheinbare z-Positionen [¬µm] (vor Korrektur)
    n_oil : float
        Brechungsindex Immersions√∂l (typisch: 1.518 f√ºr Olympus TIRF-√ñl)
    n_glass : float
        Brechungsindex Deckglas (typisch: 1.523 f√ºr High Precision Coverslide)
    n_polymer : float
        Brechungsindex Polymer/Medium (z.B. 1.47-1.49 f√ºr PMMA, 1.33 f√ºr Wasser)
    NA : float
        Numerische Apertur des Objektivs (z.B. 1.50 f√ºr Olympus UPLAPO100XOHR)
    d_glass_um : float
        Deckglas-Dicke [¬µm] (typisch: 170 ¬µm f√ºr #1.5 High Precision Slides)

    Returns:
    --------
    np.ndarray : Korrigierte z-Positionen [¬µm]

    Beispiel:
    ---------
    >>> z_app = np.array([0.0, 0.5, 1.0, 1.5, 2.0])  # ¬µm
    >>> z_corr = calculate_advanced_refractive_correction(
    ...     z_app, n_oil=1.518, n_glass=1.523, n_polymer=1.47, NA=1.50, d_glass_um=170.0
    ... )

    Referenzen:
    -----------
    - Pawley, J. (2006): Handbook of Biological Confocal Microscopy
    - Hell, S. W. (2009): Far-field optical nanoscopy
    - Diaspro, A. (2002): Confocal and Two-Photon Microscopy
    """

    # Sicherheit: Vermeide Division durch 0
    z_safe = np.where(np.abs(z_apparent) < 1e-6, 1e-6, z_apparent)

    # 1. BASIS-SKALIERUNG
    f_base = n_polymer / n_oil

    # 2. NA-ABH√ÑNGIGER TERM
    # Pr√ºfe ob NA physikalisch sinnvoll ist (NA < n_oil und NA < n_polymer)
    if NA >= n_oil or NA >= n_polymer:
        # Fallback auf einfache Korrektur wenn NA zu gro√ü
        print(f"‚ö†Ô∏è  WARNUNG: NA={NA:.3f} >= n_oil={n_oil:.3f} oder n_polymer={n_polymer:.3f}")
        print(f"    ‚Üí Verwende vereinfachte Korrektur (nur f_base)")
        f_na = 1.0
    else:
        f_na = np.sqrt(n_oil**2 - NA**2) / np.sqrt(n_polymer**2 - NA**2)

    # 3. TIEFENABH√ÑNGIGER TERM (Deckglas-Aberration)
    # WICHTIG: Dieser Term ist nur f√ºr positive z > z_threshold physikalisch g√ºltig!
    # F√ºr z ‚âà 0 oder negativ w√ºrde f_depth explodieren oder negativ werden.
    z_threshold_um = 0.1  # Minimale z-Position f√ºr Tiefenkorrektur [¬µm]

    # Berechne f_depth nur f√ºr z > z_threshold, sonst f_depth = 1.0
    f_depth = np.where(
        z_apparent > z_threshold_um,
        1.0 + (d_glass_um / np.maximum(z_apparent, z_threshold_um)) * (1.0 - n_glass / n_polymer),
        1.0  # Keine Tiefenkorrektur f√ºr z ‚â§ z_threshold
    )

    # Gesamtkorrektur
    z_corrected = z_apparent * f_base * f_na * f_depth

    return z_corrected


# ============================================================================
# ZEITABH√ÑNGIGE DIFFUSIONSKOEFFIZIENTEN
# ============================================================================

def get_time_dependent_D(t_poly_min: float, D_initial: float,
                         diffusion_type: str = "normal",
                         polymerization_acceleration_factor: float = 1.0) -> float:
    """
    Berechnet zeitabh√§ngigen Diffusionskoeffizienten w√§hrend der
    Polymerisationsphase basierend auf EXPERIMENTELLEN DATEN.

    REALISTISCHE WERTE (aus Literatur):
    ------------------------------------
    t = 0 min:    D ‚âà 2.4e-13 m¬≤/s = 0.24 ¬µm¬≤/s
    t = 90 min:   D ‚âà 5e-16 m¬≤/s = 0.0005 ¬µm¬≤/s

    ‚Üí Abfall um Faktor ~480 (2.7 Gr√∂√üenordnungen!)
    ‚Üí Exponentiell in linearer Auftragung
    ‚Üí Quasi-linear in logarithmischer Auftragung

    Physikalisches Modell:
    ----------------------
    D(t) = D‚ÇÄ ¬∑ exp(-t_eff/œÑ)

    œÑ_eff = œÑ_base / (polymerization_acceleration_factor)^2

    COMONOMER-EFFEKT (FIXED v7.1 - NICHT-LINEAR!):
    -----------------------------------------------
    polymerization_acceleration_factor steuert die Vernetzungsgeschwindigkeit:
    - 1.0 = Standard-Polymerisation (difunktional, z.B. Ethylenglykol)
    - 1.5 = Trifunktionales Comonomer ‚Üí Gelation 2.25x schneller!
    - 2.0 = Hochreaktives Comonomer ‚Üí Gelation 4x schneller!
    - 0.5 = Inhibitor/langsames Monomer ‚Üí Gelation 4x langsamer

    Physikalische Begr√ºndung:
    -------------------------
    - Vernetzungsdichte ‚àù (Funktionalit√§t)¬≤
    - Gelationszeit ‚àù 1/(Funktionalit√§t)¬≤
    - Trifunktional (Glycerol) vs Difunktional (Ethylenglykol): 5-10x schneller

    Beispiel: Glycerol (f=3) vs Ethylenglykol (f=2)
    ‚Üí factor ‚âà 3/2 = 1.5
    ‚Üí Gelation (1.5)¬≤ = 2.25x schneller ‚úì (realistisch!)

    Referenzen:
    -----------
    - Flory-Stockmayer gelation theory
    - PEG hydrogel crosslinking kinetics
    - Glycerol-based polymer networks (Nature Materials 2024)
    """

    # Base Zeitkonstante f√ºr difunktionale Monomere
    tau_base = 32.0  # [min] - Standard (difunktional)

    # NICHT-LINEARER Comonomer-Effekt (quadratisch!)
    # Gelationszeit ‚àù 1/factor¬≤
    # ‚Üí œÑ_eff = œÑ_base / factor¬≤
    tau_effective = tau_base / (polymerization_acceleration_factor ** 2)

    # Exponentieller Abfall mit angepasstem tau
    reduction_factor = np.exp(-t_poly_min / tau_effective)

    D_base = D_initial * reduction_factor

    # Diffusionstyp-spezifische Modifikationen
    # (relativ zum normalen D bei dieser Zeit)
    if diffusion_type == "subdiffusion":
        D_base *= 0.6
    elif diffusion_type == "superdiffusion":
        D_base *= 1.3
    elif diffusion_type == "confined":
        D_base *= 0.3

    return max(D_base, 1e-4)  # Minimum: 0.0001 ¬µm¬≤/s


def get_diffusion_fractions(t_poly_min: float,
                           polymerization_acceleration_factor: float = 1.0) -> Dict[str, float]:
    """
    Berechnet PHYSIKALISCH KORREKTE Fraktionen verschiedener Diffusionstypen.

    Basiert auf experimentellen Single-Particle Tracking Daten aus
    Hydrogel-Polymerisationsstudien.

    Physikalische Grundlagen:
    --------------------------
    t = 0 min (FL√úSSIG):
        - Normale Brownsche Bewegung dominiert (88%)
        - Konvektionsstr√∂me ‚Üí Superdiffusion (10%)
        - Kaum Sub/Confined (noch kein Netzwerk)

    t = 10-60 min (FR√úHE VERNETZUNG):
        - Normal bleibt dominant
        - Superdiffusion sinkt (Konvektion stoppt)
        - Sub/Confined steigen leicht (erste Netzwerke)

    t = 60-90 min (VERNETZUNG):
        - Normal sinkt deutlich
        - Superdiffusion verschwindet komplett (kein freier Fluss mehr)
        - Sub/Confined steigen stark

    t > 90 min (STARK VERNETZT):
        - Normal ~50% (bleibt signifikant! Heterogenes Netzwerk)
        - Sub + Confined ~50%
        - Superdiffusion = 0%

    COMONOMER-EFFEKT (NICHT-LINEAR!):
    ----------------------------------
    polymerization_acceleration_factor beeinflusst die Phasen√ºberg√§nge QUADRATISCH:
    - 1.0 = Standard (difunktional, z.B. Ethylenglykol)
    - 1.5 = Trifunktional (z.B. Glycerol) ‚Üí Phasen 2.25x schneller! [(1.5)¬≤ = 2.25]
    - 2.0 = Hochreaktives Comonomer ‚Üí Phasen 4x schneller! [(2.0)¬≤ = 4.0]
    - 0.7 = Inhibitor/langsam ‚Üí Phasen ~2x langsamer [(0.7)¬≤ ‚âà 0.5]

    Physik: Gelationszeit ‚àù 1/(Funktionalit√§t)¬≤ ‚Üí Phasen durchlaufen (factor)¬≤ schneller

    Referenzen:
    -----------
    - Saxton & Jacobson (1997): Single-particle tracking
    - Kusumi et al. (2005): Membrane dynamics
    - Krapf et al. (2019): Anomalous diffusion in hydrogels
    """

    # Comonomer-Beschleunigung: Effektive Zeit (NICHT-LINEAR!)
    # Gelationszeit ‚àù 1/factor¬≤ ‚Üí Phasen durchlaufen (factor)¬≤ mal schneller
    # Beispiel: factor=1.5 (Glycerol) ‚Üí Phasen 2.25x schneller
    t_effective = t_poly_min * (polymerization_acceleration_factor ** 2)

    # ========================================================================
    # PHASE 1: FL√úSSIG (t < 10 min)
    # ========================================================================
    if t_effective < 10:
        fractions = {
            "normal": 0.88,         # Haupts√§chlich Brownsch
            "superdiffusion": 0.10,  # Konvektion!
            "subdiffusion": 0.015,   # Minimal (tempor√§re Cluster)
            "confined": 0.005        # Fast keine K√§fige
        }

    # ========================================================================
    # PHASE 2: FR√úHE VERNETZUNG (10-60 min)
    # ========================================================================
    elif t_effective < 60:
        progress = (t_effective - 10.0) / 50.0  # 0 bei 10 min, 1 bei 60 min

        fractions = {
            # Normal sinkt langsam
            "normal": 0.88 - 0.08 * progress,  # 88% ‚Üí 80%

            # Superdiffusion verschwindet (Konvektion stoppt)
            "superdiffusion": 0.10 * (1.0 - progress),  # 10% ‚Üí 0%

            # Subdiffusion steigt moderat (Netzwerk bildet sich)
            "subdiffusion": 0.015 + 0.125 * progress,  # 1.5% ‚Üí 14%

            # Confined steigt leicht (erste K√§fige)
            "confined": 0.005 + 0.055 * progress  # 0.5% ‚Üí 6%
        }

    # ========================================================================
    # PHASE 3: VERNETZUNG (60-90 min)
    # ========================================================================
    elif t_effective < 90:
        progress = (t_effective - 60.0) / 30.0  # 0 bei 60 min, 1 bei 90 min

        fractions = {
            # Normal sinkt deutlich
            "normal": 0.80 - 0.25 * progress,  # 80% ‚Üí 55%

            # Superdiffusion verschwindet komplett
            "superdiffusion": 0.0,

            # Subdiffusion steigt stark (Netzwerk verdichtet)
            "subdiffusion": 0.14 + 0.16 * progress,  # 14% ‚Üí 30%

            # Confined steigt stark (viele K√§fige)
            "confined": 0.06 + 0.09 * progress  # 6% ‚Üí 15%
        }

    # ========================================================================
    # PHASE 4: STARK VERNETZT (90-120 min)
    # ========================================================================
    elif t_effective < 120:
        progress = (t_effective - 90.0) / 30.0  # 0 bei 90 min, 1 bei 120 min

        fractions = {
            # Normal sinkt weiter auf ~50%
            "normal": 0.55 - 0.05 * progress,  # 55% ‚Üí 50%

            # Superdiffusion = 0
            "superdiffusion": 0.0,

            # Subdiffusion steigt weiter
            "subdiffusion": 0.30 + 0.05 * progress,  # 30% ‚Üí 35%

            # Confined steigt auf ~15%
            "confined": 0.15 + 0.00 * progress  # 15% ‚Üí 15%
        }

    # ========================================================================
    # PHASE 5: VOLLST√ÑNDIG VERNETZT (> 120 min)
    # ========================================================================
    else:
        # Plateau erreicht
        fractions = {
            "normal": 0.50,         # 50% normale Diffusion bleibt!
            "superdiffusion": 0.0,  # Keine Konvektion mehr
            "subdiffusion": 0.35,   # 35% anomale Diffusion
            "confined": 0.15        # 15% eingesperrt in K√§figen
        }

    # Normalisierung (Sicherheit)
    total = sum(fractions.values())
    return {k: v/total for k, v in fractions.items()}


# ============================================================================
# DIFFUSION SWITCHER - Dynamisches Wechseln zwischen Diffusionsarten
# ============================================================================

class DiffusionSwitcher:
    """
    Verwaltet dynamisches Switching zwischen Diffusionsarten w√§hrend Trajektorien.

    Physikalische Motivation:
    --------------------------
    In realen Hydrogelen k√∂nnen Partikel zwischen verschiedenen Diffusionsarten
    wechseln:

    1. NORMAL ‚Üí CONFINED: Partikel wird in Pore gefangen
    2. CONFINED ‚Üí NORMAL: Partikel entkommt aus Pore
    3. NORMAL ‚Üí SUB: Partikel trifft auf Netzwerk-Hindernis
    4. SUB ‚Üí NORMAL: Partikel √ºberwindet Hindernis
    5. SUPER ‚Üí NORMAL: Konvektion stoppt bei Vernetzung

    Switching-Wahrscheinlichkeit h√§ngt ab von:
    - Polymerisationszeit (mehr Vernetzung ‚Üí h√§ufigeres Switching)
    - Aktuellem Diffusionstyp
    - Lokaler Netzwerkdichte

    Referenzen:
    -----------
    - Metzler et al. (2014): Anomalous diffusion models
    - Weigel et al. (2011): Ergodic and nonergodic processes
    """

    def __init__(self, t_poly_min: float, base_switch_prob: float = 0.002):
        """
        Parameters:
        -----------
        t_poly_min : float
            Polymerisationszeit [min]
        base_switch_prob : float
            Basis-Switching-Wahrscheinlichkeit pro Frame (default: 0.2%)
            OPTIMIERT: Reduziert von 1% auf 0.2% f√ºr realistischere Switching-Raten
        """
        self.t_poly_min = t_poly_min
        self.base_switch_prob = base_switch_prob

        # Berechne Switching-Wahrscheinlichkeit basierend auf Vernetzungsgrad
        self.switch_prob = self._calculate_switch_probability()

    def _calculate_switch_probability(self) -> float:
        """
        Berechnet Switching-Wahrscheinlichkeit basierend auf Polymerisationszeit.

        Logik:
        ------
        - t < 30 min: Wenig Switching (homogenes Medium)
        - t = 30-90 min: Zunehmendes Switching (Netzwerk bildet sich)
        - t > 90 min: Hohes Switching (heterogenes Netzwerk)
        """

        if self.t_poly_min < 30:
            # Fr√ºh: wenig Switching
            return self.base_switch_prob * 0.5

        elif self.t_poly_min < 90:
            # Mittlere Phase: linearer Anstieg
            progress = (self.t_poly_min - 30.0) / 60.0
            return self.base_switch_prob * (0.5 + 2.0 * progress)  # 0.5x ‚Üí 2.5x

        else:
            # Sp√§t: viel Switching (heterogenes Netzwerk)
            return self.base_switch_prob * 2.5

    def should_switch(self, current_type: str) -> bool:
        """
        Entscheidet, ob ein Switch stattfinden soll.

        Parameters:
        -----------
        current_type : str
            Aktueller Diffusionstyp

        Returns:
        --------
        bool : True wenn Switch erfolgen soll
        """

        # Typ-spezifische Modifikation
        type_modifier = {
            "normal": 1.0,       # Normal: Standard-Switching
            "subdiffusion": 0.7,  # Sub: etwas stabiler (im Netzwerk gefangen)
            "confined": 1.5,      # Confined: instabil (versucht zu entkommen)
            "superdiffusion": 2.0  # Super: sehr instabil (Konvektion stoppt)
        }

        effective_prob = self.switch_prob * type_modifier.get(current_type, 1.0)

        return np.random.random() < effective_prob

    def get_new_type(self, current_type: str,
                     fractions: Dict[str, float]) -> str:
        """
        W√§hlt neuen Diffusionstyp basierend auf physikalischen √úberg√§ngen.

        Parameters:
        -----------
        current_type : str
            Aktueller Typ
        fractions : Dict[str, float]
            Aktuelle Fraktionen aller Typen

        Returns:
        --------
        str : Neuer Diffusionstyp
        """

        # Definiere erlaubte √úberg√§nge (physikalisch sinnvoll)
        transitions = {
            "normal": {
                "normal": 0.2,        # Bleibt normal
                "subdiffusion": 0.5,  # Trifft auf Hindernis
                "confined": 0.3,      # Wird gefangen
                "superdiffusion": 0.0  # Kein √úbergang zu super
            },
            "subdiffusion": {
                "normal": 0.6,        # √úberwindet Hindernis
                "subdiffusion": 0.2,  # Bleibt sub
                "confined": 0.2,      # Wird st√§rker gefangen
                "superdiffusion": 0.0
            },
            "confined": {
                "normal": 0.5,        # Entkommt!
                "subdiffusion": 0.3,  # Teilweise frei
                "confined": 0.2,      # Bleibt gefangen
                "superdiffusion": 0.0
            },
            "superdiffusion": {
                "normal": 0.8,        # Konvektion stoppt ‚Üí normal
                "subdiffusion": 0.2,  # Direkt ins Netzwerk
                "confined": 0.0,
                "superdiffusion": 0.0  # Super verschwindet
            }
        }

        # Hole √úbergangswahrscheinlichkeiten
        trans_probs = transitions.get(current_type, {})

        # W√§hle neuen Typ
        types = list(trans_probs.keys())
        probs = list(trans_probs.values())

        # Normalisierung
        total = sum(probs)
        if total > 0:
            probs = [p / total for p in probs]
        else:
            # Fallback: verwende globale Fraktionen
            types = list(fractions.keys())
            probs = list(fractions.values())

        # Random Choice
        new_type = np.random.choice(types, p=probs)

        return new_type


# ============================================================================
# PSF GENERATOR - OPTIMIERT mit Vektorisierung
# ============================================================================

class PSFGeneratorOptimized:
    """
    OPTIMIERTE PSF-Generierung mit vektorisierten Batch-Operationen!

    Performance-Verbesserungen:
    - 10-20x schneller durch Batch-Processing
    - ROI-basierte Berechnung (nur 3-sigma Umgebung)
    - Pre-computed Koordinaten-Grids
    - Optimierte NumPy-Operationen

    Physik bleibt identisch zu V3.0!
    """

    def __init__(self, detector: DetectorPreset, astigmatism: bool = False):
        self.detector = detector
        self.astigmatism = astigmatism

        # FWHM zu sigma
        fwhm_px = detector.fwhm_um / detector.pixel_size_um
        self.sigma_px = fwhm_px / 2.355
        self._sigma_eps = 1e-6

        # Astigmatismus-Parameter und Brechungsindex-Korrektur
        meta = getattr(detector, 'metadata', {}) or {}
        if astigmatism:
            # NEUE PHYSIKALISCH KORREKTE PARAMETER
            self.focal_offset_um = float(meta.get("astig_focal_offset_um", 0.4))  # Halbe Fokustrennung
            self.z_rayleigh_um = float(meta.get("astig_z_rayleigh_um", 0.6))  # Rayleigh-Bereich

            # Backward compatibility: Fallback auf alte Parameter falls neue nicht vorhanden
            if "astig_z0_um" in meta and "astig_focal_offset_um" not in meta:
                # Legacy-Modus: Verwende alte Koeffizienten
                self.use_legacy_astig = True
                self.z0_um = float(meta.get("astig_z0_um", 0.5))
                coeffs = meta.get("astig_coeffs", {}) or {}
                self.Ax = float(coeffs.get("A_x", 1.0))
                self.Bx = float(coeffs.get("B_x", 0.0))
                self.Ay = float(coeffs.get("A_y", 1.0))  # Jetzt IMMER positiv!
                self.By = float(coeffs.get("B_y", 0.0))
            else:
                self.use_legacy_astig = False

            # ERWEITERTE Brechungsindex-Korrektur (NEU!)
            self.use_advanced_correction = bool(meta.get("use_advanced_refractive_correction", False))
            if self.use_advanced_correction:
                # Lade alle Parameter f√ºr erweiterte Korrektur
                self.n_oil = float(meta.get("n_oil", 1.518))
                self.n_glass = float(meta.get("n_glass", 1.523))
                self.n_polymer = float(meta.get("n_polymer", 1.47))
                self.NA = float(meta.get("NA", 1.50))
                self.d_glass_um = float(meta.get("d_glass_um", 170.0))
                self.refractive_correction = None  # Nicht verwendet bei erweiterter Korrektur
            else:
                # Legacy: Einfacher Korrekturfaktor
                self.refractive_correction = float(meta.get("refractive_index_correction", 1.0))
                self.use_advanced_correction = False
        else:
            self.refractive_correction = 1.0
            self.use_advanced_correction = False
            self.use_legacy_astig = False

        # Pre-compute grids
        self._coord_grids = {}

    def _get_coordinate_grids(self, image_size: Tuple[int, int]):
        """Pre-computed coordinate grids."""
        if image_size not in self._coord_grids:
            height, width = image_size
            y, x = np.meshgrid(np.arange(height, dtype=np.float32),
                              np.arange(width, dtype=np.float32), indexing='ij')
            self._coord_grids[image_size] = (x, y)
        return self._coord_grids[image_size]

    def generate_psf_batch(self, positions: np.ndarray, intensities: np.ndarray,
                          z_positions: np.ndarray, image_size: Tuple[int, int]) -> np.ndarray:
        """
        OPTIMIERT: Generiert mehrere PSFs gleichzeitig (vektorisiert).

        10-20x schneller als einzelne PSF-Generierung!

        Parameters:
        -----------
        positions : np.ndarray
            Spot-Positionen, shape (n_spots, 2) [px] - (x, y)
        intensities : np.ndarray
            Peak-Intensit√§ten, shape (n_spots,) [counts]
        z_positions : np.ndarray
            z-Positionen, shape (n_spots,) [¬µm]
        image_size : Tuple[int, int]
            Bildgr√∂√üe (height, width) [px]

        Returns:
        --------
        np.ndarray : Summierte PSFs [counts], shape (height, width)
        """

        x_grid, y_grid = self._get_coordinate_grids(image_size)
        height, width = image_size
        n_spots = len(positions)

        # Berechne alle sigmas auf einmal
        if self.astigmatism:
            # Brechungsindex-Korrektur auf z-Positionen anwenden
            if self.use_advanced_correction:
                # ERWEITERTE PHYSIKALISCHE KORREKTUR (NEU!)
                z_corrected = calculate_advanced_refractive_correction(
                    z_positions,
                    n_oil=self.n_oil,
                    n_glass=self.n_glass,
                    n_polymer=self.n_polymer,
                    NA=self.NA,
                    d_glass_um=self.d_glass_um
                )
            else:
                # Legacy: Einfache Korrektur
                z_corrected = z_positions * self.refractive_correction

            if self.use_legacy_astig:
                # Legacy polynomial formula (backward compatibility)
                z_norm = z_corrected / self.z0_um
                term_x = 1.0 + self.Ax * (z_norm**2) + self.Bx * (z_norm**4)
                term_y = 1.0 + self.Ay * (z_norm**2) + self.By * (z_norm**4)
                term_x = np.maximum(term_x, self._sigma_eps)
                term_y = np.maximum(term_y, self._sigma_eps)
                sigma_x = self.sigma_px * np.sqrt(term_x)
                sigma_y = self.sigma_px * np.sqrt(term_y)
            else:
                # NEUE PHYSIKALISCH KORREKTE FORMEL (Huang et al. 2008)
                # œÉ_x(z) = œÉ_0 * sqrt(1 + ((z - z_fx) / z_R)^2)
                # œÉ_y(z) = œÉ_0 * sqrt(1 + ((z - z_fy) / z_R)^2)
                # c = focal_offset_um
                # z_R = Rayleigh-Bereich (depth of focus)
                #
                # Convention: x-Fokus bei +c, y-Fokus bei -c
                # Ergebnis: z<0 ‚Üí horizontal, z=0 ‚Üí rund, z>0 ‚Üí vertikal

                c = self.focal_offset_um
                z_R = self.z_rayleigh_um

                # x-Achse: Fokus bei z = +c (oberhalb der Fokusebene)
                term_x = 1.0 + ((z_corrected - (+c)) / z_R)**2
                # y-Achse: Fokus bei z = -c (unterhalb der Fokusebene)
                term_y = 1.0 + ((z_corrected - (-c)) / z_R)**2

                sigma_x = self.sigma_px * np.sqrt(term_x)
                sigma_y = self.sigma_px * np.sqrt(term_y)
        else:
            sigma_x = np.full(n_spots, self.sigma_px, dtype=np.float32)
            sigma_y = np.full(n_spots, self.sigma_px, dtype=np.float32)

        # Initialisiere Frame
        frame = np.zeros((height, width), dtype=np.float32)

        # Berechne PSFs f√ºr alle Spots (mit ROI-Optimierung)
        for i in range(n_spots):
            if intensities[i] <= 0:
                continue

            cx, cy = positions[i]
            sx, sy = max(sigma_x[i], self._sigma_eps), max(sigma_y[i], self._sigma_eps)

            # ROI-Optimierung: Nur 3-sigma Umgebung berechnen
            cutoff = 3.5
            x_min = int(max(0, cx - cutoff * sx))
            x_max = int(min(width, cx + cutoff * sx + 1))
            y_min = int(max(0, cy - cutoff * sy))
            y_max = int(min(height, cy + cutoff * sy + 1))

            if x_max <= x_min or y_max <= y_min:
                continue

            # Lokale Koordinaten
            x_local = x_grid[y_min:y_max, x_min:x_max]
            y_local = y_grid[y_min:y_max, x_min:x_max]

            # Gau√üfunktion (vektorisiert)
            psf_local = intensities[i] * np.exp(
                -(((x_local - cx)**2 / (2 * sx**2)) +
                  ((y_local - cy)**2 / (2 * sy**2)))
            )

            frame[y_min:y_max, x_min:x_max] += psf_local

        return frame

    def get_metadata(self) -> Dict:
        """Gibt PSF-Metadata zur√ºck"""
        meta = {
            "fwhm_um": self.detector.fwhm_um,
            "sigma_px": self.sigma_px,
            "pixel_size_um": self.detector.pixel_size_um,
            "astigmatism": self.astigmatism,
            "optimized": True
        }

        if self.astigmatism:
            if self.use_legacy_astig:
                meta.update({
                    "astigmatism_mode": "legacy_polynomial",
                    "z0_um": self.z0_um,
                    "Ax": self.Ax,
                    "Ay": self.Ay
                })
            else:
                meta.update({
                    "astigmatism_mode": "physical_defocus",
                    "focal_offset_um": self.focal_offset_um,
                    "z_rayleigh_um": self.z_rayleigh_um
                })

        return meta


# ============================================================================
# TRAJEKTORIEN-GENERATOR
# ============================================================================

class TrajectoryGenerator:
    """Generiert realistische Trajektorien basierend auf Diffusionsmodellen."""

    def __init__(self, D_initial: float, t_poly_min: float,
                 frame_rate_hz: float, pixel_size_um: float,
                 enable_switching: bool = True,
                 base_switch_prob: float = 0.01,
                 polymerization_acceleration_factor: float = 1.0):
        self.D_initial = D_initial
        self.t_poly_min = t_poly_min
        self.dt = 1.0 / frame_rate_hz
        self.pixel_size_um = pixel_size_um
        self.enable_switching = enable_switching
        self._base_switch_prob = float(base_switch_prob)
        self.polymerization_acceleration_factor = polymerization_acceleration_factor

        # Hole Diffusionsfraktionen (mit Comonomer-Faktor)
        self.fractions = get_diffusion_fractions(t_poly_min, polymerization_acceleration_factor)

        # Berechne D-Werte f√ºr jeden Typ (mit Comonomer-Faktor)
        self.D_values = {
            dtype: get_time_dependent_D(t_poly_min, D_initial, dtype, polymerization_acceleration_factor)
            for dtype in self.fractions.keys()
        }

        # NEU: Initialisiere Diffusion Switcher f√ºr dynamisches Switching
        if enable_switching:
            self.switcher = DiffusionSwitcher(
                t_poly_min=t_poly_min,
                base_switch_prob=self._base_switch_prob  # 1% pro Frame
            )
        else:
            self.switcher = None

    def _create_switcher(self) -> Optional['DiffusionSwitcher']:
        if not self.enable_switching:
            return None
        return DiffusionSwitcher(
            t_poly_min=self.t_poly_min,
            base_switch_prob=self._base_switch_prob
        )

    def generate_trajectory(self, start_pos: Tuple[float, float, float],
                           num_frames: int,
                           diffusion_type: str = "normal",
                           switcher: Optional['DiffusionSwitcher'] = None,
                           max_switches: Optional[int] = None) -> Tuple[np.ndarray, List[Dict]]:
        """
        Generiert eine 3D-Trajektorie mit ANISOTROPER Diffusion und
        DYNAMISCHEM SWITCHING zwischen Diffusionsarten.

        WICHTIG: z-Diffusion ist VIEL LANGSAMER als x,y!
        ------------------------------------------------
        - Dxy (lateral): normale Diffusion
        - Dz (axial): ~5-10x langsamer

        NEU: Dynamisches Switching
        --------------------------
        - Partikel k√∂nnen zwischen Diffusionsarten wechseln
        - Switching-Wahrscheinlichkeit abh√§ngig von Vernetzungsgrad
        - Physikalisch erlaubte √úberg√§nge (z.B. normal ‚Üí confined)

        Grund f√ºr Anisotropie:
        - Membran-N√§he (TIRF-Mikroskopie)
        - Oberfl√§cheninteraktionen
        - Geometrische Constraints
        - Hydrogel-Anisotropie

        Physikalisch korrekte Implementation:
        - œÉxy = ‚àö(2 * Dxy * Œît^Œ±)
        - œÉz = ‚àö(2 * Dz * Œît^Œ±)  mit Dz << Dxy

        Returns:
        --------
        Tuple[np.ndarray, List[Dict]]:
            - trajectory: (num_frames, 3) array [¬µm]
            - switch_log: Liste von Switches {"frame": int, "from": str, "to": str}
        """

        current_type = diffusion_type
        trajectory = np.zeros((num_frames, 3), dtype=np.float32)
        trajectory[0] = start_pos
        switch_log = []
        active_switcher = switcher if switcher is not None else self.switcher
        performed_switches = 0

        # z-Diffusion ist DEUTLICH LANGSAMER!
        # Typisch: Faktor 5-10 langsamer als lateral
        z_diffusion_factor = 0.15  # z ist 6.7x langsamer als x,y

        for i in range(1, num_frames):
            # NEU: Pr√ºfe ob Switch erfolgt (nur wenn Switcher aktiviert)
            if active_switcher is not None and active_switcher.should_switch(current_type):
                new_type = active_switcher.get_new_type(current_type, self.fractions)
                if new_type != current_type:
                    # Logge Switch
                    switch_log.append({
                        "frame": i,
                        "from": current_type,
                        "to": new_type
                    })
                    current_type = new_type
                    performed_switches += 1
                    if max_switches is not None and performed_switches >= max_switches:
                        active_switcher = None

            # Verwende aktuellen Typ f√ºr diesen Frame
            D = self.D_values[current_type]
            D_z = D * z_diffusion_factor

            # Anomaler Exponent (ST√ÑRKERE WERTE f√ºr bessere Unterscheidbarkeit!)
            # Literatur: sub = 0.3-0.7, normal = 1.0, super = 1.3-1.8
            alpha = 0.5 if current_type == "subdiffusion" else 1.0
            if current_type == "superdiffusion":
                alpha = 1.5

            # Lateral (x, y) - volle Diffusion
            sigma_xy = np.sqrt(2.0 * D * (self.dt ** alpha))

            # Axial (z) - stark reduziert!
            sigma_z = np.sqrt(2.0 * D_z * (self.dt ** alpha))

            # Brownsche Schritte (ANISOTROP!)
            step_xy = np.random.normal(0, sigma_xy, size=2).astype(np.float32)
            step_z = np.random.normal(0, sigma_z, size=1).astype(np.float32)
            step = np.concatenate([step_xy, step_z])

            # Confined Diffusion: R√ºckstellkraft (ST√ÑRKER f√ºr bessere Erkennbarkeit!)
            if current_type == "confined":
                confinement_length = 0.3  # ¬µm (kleiner = st√§rkeres Confinement)
                k = D / (confinement_length ** 2)
                drift = -k * self.dt * (trajectory[i-1] - start_pos)
                # z-Confinement ist st√§rker!
                drift[2] *= 2.0
            else:
                drift = np.zeros(3, dtype=np.float32)

            trajectory[i] = trajectory[i-1] + step + drift

        return trajectory, switch_log

    def generate_multi_trajectory(self, num_spots: int, num_frames: int,
                                  image_size: Tuple[int, int],
                                  force_diffusion_type: Optional[str] = None,
                                  per_type_counts: Optional[Dict[str, int]] = None,
                                  enable_switching: Optional[bool] = None,
                                  max_switches: Optional[int] = None) -> List[Dict]:
        """
        Generiert mehrere Trajektorien mit verschiedenen Diffusionstypen
        und dynamischem Switching.

        Returns:
        --------
        List[Dict]: Liste von Trajektorien mit Metadata:
            - positions: (num_frames, 3) array
            - diffusion_type: Initial diffusion type
            - D_value: Diffusion coefficient
            - switch_log: Liste von Switches (NEU!)
            - num_switches: Anzahl Switches (NEU!)
        """

        height, width = image_size
        trajectories = []

        allow_switching = self.enable_switching if enable_switching is None else enable_switching

        if per_type_counts:
            generation_plan = []
            for dtype, count in per_type_counts.items():
                if count <= 0:
                    continue
                generation_plan.extend([dtype] * int(count))
        else:
            generation_plan = []
            for _ in range(num_spots):
                if force_diffusion_type:
                    dtype = force_diffusion_type
                else:
                    dtype = np.random.choice(
                        list(self.fractions.keys()),
                        p=list(self.fractions.values())
                    )
                generation_plan.append(dtype)

        for dtype in generation_plan:
            if dtype not in self.D_values:
                dtype = "normal"

            # Zuf√§llige Startposition
            start_x = np.random.uniform(0.2 * width, 0.8 * width) * self.pixel_size_um
            start_y = np.random.uniform(0.2 * height, 0.8 * height) * self.pixel_size_um
            start_z = np.random.uniform(-0.5, 0.5)

            # Generiere Trajektorie MIT Switch-Log
            switcher = self._create_switcher() if allow_switching else None
            trajectory, switch_log = self.generate_trajectory(
                (start_x, start_y, start_z),
                num_frames,
                dtype,
                switcher=switcher,
                max_switches=max_switches
            )

            trajectories.append({
                "positions": trajectory,
                "diffusion_type": dtype,  # Initialer Typ
                "D_value": self.D_values.get(dtype, self.D_initial),
                "switch_log": switch_log,  # NEU: Alle Switches
                "num_switches": len(switch_log)  # NEU: Anzahl Switches
            })

        return trajectories

    def get_metadata(self) -> Dict:
        """Gibt Trajektorien-Metadata zur√ºck"""
        return {
            "D_initial": self.D_initial,
            "t_poly_min": self.t_poly_min,
            "frame_rate_hz": 1.0 / self.dt,
            "diffusion_fractions": self.fractions,
            "D_values": self.D_values,
            "enable_switching": bool(self.enable_switching),
            "base_switch_prob": float(self._base_switch_prob),
        }


# ============================================================================
# BACKGROUND GENERATOR - OPTIMIERT
# ============================================================================

class BackgroundGeneratorOptimized:
    """Generiert realistischen Background mit Pre-Computing und optionalem Ausleuchtungsgradienten."""

    def __init__(self, mean: float, std: float,
                 illumination_gradient_strength: float = 0.0,
                 illumination_gradient_type: str = "radial"):
        """
        Parameters:
        -----------
        mean : float
            Mittlerer Background [counts]
        std : float
            Standardabweichung des Backgrounds [counts]
        illumination_gradient_strength : float
            St√§rke des Ausleuchtungsgradienten [counts].
            0.0 = kein Gradient (Standard)
            5.0-20.0 = subtiler, realistischer Gradient
            >20.0 = starker Gradient
        illumination_gradient_type : str
            Typ des Gradienten:
            - "radial": Radial von Zentrum nach au√üen (Standard)
            - "linear_x": Linear entlang x-Achse
            - "linear_y": Linear entlang y-Achse
            - "corner": Gradient von einer Ecke
        """
        self.mean = mean
        self.std = std
        self.gradient_strength = illumination_gradient_strength
        self.gradient_type = illumination_gradient_type
        self._cache = {}

    def generate(self, image_size: Tuple[int, int], use_cache: bool = True) -> np.ndarray:
        """
        Generiert Background-Bild mit optionalem Ausleuchtungsgradienten.

        Mit Cache f√ºr wiederholte Gr√∂√üen (schneller f√ºr Batch-Processing).
        """

        if use_cache and image_size in self._cache:
            # Kopiere gecachten Background + frisches Rauschen
            bg_base = self._cache[image_size].copy()
            noise = np.random.normal(0, self.std / 2, size=image_size).astype(np.float32)
            return bg_base + noise

        height, width = image_size

        # Basis-Background (Poisson)
        background = np.random.poisson(self.mean, size=(height, width)).astype(np.float32)

        # Gau√üsches Rauschen
        noise = np.random.normal(0, self.std, size=(height, width)).astype(np.float32)
        background += noise

        # Ausleuchtungsgradient (hyperrealistisch)
        if self.gradient_strength > 0:
            y, x = np.meshgrid(np.linspace(-1, 1, height, dtype=np.float32),
                              np.linspace(-1, 1, width, dtype=np.float32),
                              indexing='ij')

            if self.gradient_type == "radial":
                # Radialer Gradient (Standard): Zentrum heller, R√§nder dunkler
                # Simuliert typische Ausleuchtung bei Mikroskopen
                r_squared = x**2 + y**2
                gradient = self.gradient_strength * r_squared

            elif self.gradient_type == "linear_x":
                # Linearer Gradient entlang x-Achse
                gradient = self.gradient_strength * (x + 1.0) / 2.0

            elif self.gradient_type == "linear_y":
                # Linearer Gradient entlang y-Achse
                gradient = self.gradient_strength * (y + 1.0) / 2.0

            elif self.gradient_type == "corner":
                # Gradient von Ecke (0,0) nach (max,max)
                gradient = self.gradient_strength * (x + y + 2.0) / 4.0

            else:
                # Fallback auf radialen Gradient
                r_squared = x**2 + y**2
                gradient = self.gradient_strength * r_squared

            background += gradient

        if use_cache:
            self._cache[image_size] = background.copy()

        return np.maximum(background, 0)


# ============================================================================
# PHOTOPHYSICS - Blinking & Bleaching
# ============================================================================

class PhotoPhysics:
    """Einfache 2-Zustands-Photophysik (ON/OFF) mit Bleaching."""

    def __init__(self, on_mean_frames: float = 4.0, off_mean_frames: float = 6.0,
                 bleach_prob_per_frame: float = 0.002):
        self.on_mean = max(on_mean_frames, 1e-3)
        self.off_mean = max(off_mean_frames, 1e-3)
        self.bleach_prob = max(bleach_prob_per_frame, 0.0)

    def _sample_duration(self, mean_frames: float) -> int:
        p = 1.0 / max(mean_frames, 1.0)
        return int(np.random.geometric(p))

    def generate_on_mask(self, num_spots: int, num_frames: int) -> np.ndarray:
        """Generiert ON/OFF-Maske f√ºr alle Spots."""
        mask = np.zeros((num_spots, num_frames), dtype=bool)
        p0_on = self.on_mean / (self.on_mean + self.off_mean)

        for s in range(num_spots):
            t = 0
            state_on = np.random.rand() < p0_on
            bleached = False

            while t < num_frames:
                if bleached:
                    break

                duration = self._sample_duration(self.on_mean if state_on else self.off_mean)
                end = min(num_frames, t + duration)

                if state_on:
                    mask[s, t:end] = True
                    # Bleaching
                    if np.random.rand() < (1.0 - (1.0 - self.bleach_prob) ** (end - t)):
                        bleached = True
                        break

                t = end
                state_on = not state_on

        return mask


# ============================================================================
# HAUPTSIMULATOR - OPTIMIERT
# ============================================================================

class TIFFSimulatorOptimized:
    """
    OPTIMIERTE Hauptklasse f√ºr TIFF-Simulation.

    Performance-Verbesserungen:
    - 10-50x schneller f√ºr gro√üe TIFFs
    - Batch-Processing f√ºr Spots
    - Pre-computed Backgrounds
    - Optimierte Speicherverwaltung
    - Progress-Callbacks f√ºr UI

    Physik bleibt identisch!
    """

    def __init__(self, detector: DetectorPreset, mode: str = "polyzeit",
                 t_poly_min: float = 60.0, astigmatism: bool = False,
                 polymerization_acceleration_factor: float = 1.0):

        self.detector = detector
        self.mode = mode
        self.t_poly_min = t_poly_min
        self.astigmatism = astigmatism

        # Comonomer-Beschleunigungsfaktor (kann auch aus Metadata kommen)
        meta = detector.metadata or {}
        self.polymerization_acceleration_factor = float(meta.get(
            "polymerization_acceleration_factor",
            polymerization_acceleration_factor
        ))

        # Initialisiere Generatoren (OPTIMIERT)
        self.psf_gen = PSFGeneratorOptimized(detector, astigmatism)

        # Ausleuchtungsgradient-Parameter aus Metadata
        gradient_strength = float(meta.get("illumination_gradient_strength", 0.0))
        gradient_type = str(meta.get("illumination_gradient_type", "radial"))

        self.bg_gen = BackgroundGeneratorOptimized(
            detector.background_mean,
            detector.background_std,
            illumination_gradient_strength=gradient_strength,
            illumination_gradient_type=gradient_type
        )

        # Metadata
        self.metadata = {
            "detector": detector.name,
            "mode": mode,
            "t_poly_min": t_poly_min,
            "astigmatism": astigmatism,
            "timestamp": datetime.now().isoformat(),
            "version": "4.0_optimized"
        }

    def generate_tiff(self, image_size: Tuple[int, int], num_spots: int,
                     num_frames: int, frame_rate_hz: float,
                     d_initial: float = 0.5,
                     exposure_substeps: int = 1,
                     enable_photophysics: bool = False,
                     trajectory_options: Optional[Dict[str, object]] = None,
                     progress_callback: Optional[Callable[[int, int, str], None]] = None) -> np.ndarray:
        """
        Generiert TIFF-Stack (OPTIMIERT).

        Parameters:
        -----------
        progress_callback : Callable, optional
            Callback-Funktion f√ºr Progress-Updates: callback(current_frame, total_frames, status_msg)

        Returns:
        --------
        np.ndarray : TIFF-Stack (num_frames, height, width) [counts]
        """

        height, width = image_size

        # Trajektorien-Optionen
        traj_options = trajectory_options or {}
        per_type_counts = traj_options.get("per_type_counts")
        if per_type_counts:
            try:
                num_spots_effective = int(sum(int(v) for v in per_type_counts.values()))
            except Exception:
                num_spots_effective = int(num_spots)
        else:
            num_spots_effective = int(num_spots)

        enable_switching_override = traj_options.get("enable_switching")
        max_switches = traj_options.get("max_switches")
        force_diffusion_type = traj_options.get("force_diffusion_type")

        # Initialisiere Trajektorien-Generator
        traj_gen = TrajectoryGenerator(
            D_initial=float(d_initial),
            t_poly_min=self.t_poly_min,
            frame_rate_hz=frame_rate_hz,
            pixel_size_um=self.detector.pixel_size_um,
            enable_switching=bool(traj_options.get("enable_switching", True)),
            polymerization_acceleration_factor=self.polymerization_acceleration_factor
        )

        # Generiere Trajektorien
        if progress_callback:
            progress_callback(0, num_frames, "Generiere Trajektorien...")

        trajectories = traj_gen.generate_multi_trajectory(
            num_spots_effective,
            num_frames,
            image_size,
            force_diffusion_type=force_diffusion_type,
            per_type_counts=per_type_counts,
            enable_switching=enable_switching_override,
            max_switches=max_switches
        )

        # Detector-Parameter
        meta = self.detector.metadata or {}
        read_noise_std = float(meta.get("read_noise_std", 1.5))
        spot_sigma = float(meta.get("spot_intensity_sigma", 0.25))
        frame_sigma = float(meta.get("frame_jitter_sigma", 0.10))
        on_mean = float(meta.get("on_mean_frames", 4.0))
        off_mean = float(meta.get("off_mean_frames", 6.0))
        bleach_p = float(meta.get("bleach_prob_per_frame", 0.002))
        z_amp_um = float(meta.get("z_amp_um", 0.7))
        z_max_um = float(meta.get("z_max_um", 0.6))

        # Photophysik
        if enable_photophysics:
            if progress_callback:
                progress_callback(0, num_frames, "Berechne Photophysik (Blinking/Bleaching)...")
            phot = PhotoPhysics(on_mean, off_mean, bleach_p)
            on_mask = phot.generate_on_mask(num_spots_effective, num_frames)
        else:
            on_mask = np.ones((num_spots_effective, num_frames), dtype=bool)

        # Spot-Intensit√§ten (Lognormal)
        base_intensities = self.detector.max_intensity * np.exp(
            np.random.normal(0.0, spot_sigma, size=num_spots_effective)
        ).astype(np.float32)

        # Initialisiere TIFF-Stack
        tiff_stack = np.zeros((num_frames, height, width), dtype=np.uint16)

        # Generiere jeden Frame (OPTIMIERT mit Batch-PSF)
        for frame_idx in range(num_frames):
            if progress_callback and frame_idx % max(1, num_frames // 20) == 0:
                progress_callback(frame_idx, num_frames, f"Rendere Frame {frame_idx+1}/{num_frames}")

            # Background
            frame = self.bg_gen.generate(image_size, use_cache=True)

            # Sammle alle aktiven Spots f√ºr diesen Frame
            active_spots = []
            spot_positions = []
            spot_intensities = []
            spot_z_positions = []

            for si, traj_data in enumerate(trajectories):
                if not on_mask[si, frame_idx]:
                    continue

                pos = traj_data["positions"][frame_idx]
                x_px = pos[0] / self.detector.pixel_size_um
                y_px = pos[1] / self.detector.pixel_size_um
                z_um = float(pos[2]) if self.astigmatism else 0.0

                # z-Clipping
                if self.astigmatism:
                    z_um = np.clip(z_um, -z_max_um, z_max_um)

                # Check ob im Bild
                if 0 <= x_px < width and 0 <= y_px < height:
                    # Frame jitter & z-intensity falloff
                    frame_jitter = float(np.exp(np.random.normal(0.0, frame_sigma)))
                    amp = np.exp(- (z_um / z_amp_um) ** 2) if self.astigmatism else 1.0
                    intensity = base_intensities[si] * frame_jitter * amp

                    # Motion Blur: Substeps
                    substeps = max(int(exposure_substeps), 1)
                    if frame_idx > 0 and substeps > 1:
                        prev = traj_data["positions"][frame_idx-1]
                    else:
                        prev = pos

                    for ss in range(substeps):
                        if frame_idx > 0 and substeps > 1:
                            frac = (ss + 0.5) / substeps
                            px = prev[0] + frac * (pos[0] - prev[0])
                            py = prev[1] + frac * (pos[1] - prev[1])
                            pz = prev[2] + frac * (pos[2] - prev[2]) if self.astigmatism else 0.0
                        else:
                            px, py, pz = pos[0], pos[1], z_um

                        spot_positions.append([px / self.detector.pixel_size_um,
                                              py / self.detector.pixel_size_um])
                        spot_intensities.append(intensity / substeps)
                        spot_z_positions.append(float(pz) if self.astigmatism else 0.0)

            # BATCH-PSF-Generierung (VIEL schneller!)
            if len(spot_positions) > 0:
                positions_arr = np.array(spot_positions, dtype=np.float32)
                intensities_arr = np.array(spot_intensities, dtype=np.float32)
                z_positions_arr = np.array(spot_z_positions, dtype=np.float32)

                psf_batch = self.psf_gen.generate_psf_batch(
                    positions_arr, intensities_arr, z_positions_arr, image_size
                )
                frame += psf_batch

            # Poisson-Noise (robuste Vorverarbeitung)
            frame = np.nan_to_num(frame, nan=0.0, posinf=1e6, neginf=0.0)
            frame = np.clip(frame, 0, 1e6)
            frame = np.random.poisson(frame).astype(np.float32)

            # Kamera-Read-Noise
            if read_noise_std > 0:
                frame += np.random.normal(0.0, read_noise_std, size=frame.shape).astype(np.float32)

            # Clip & Convert
            tiff_stack[frame_idx] = np.clip(frame, 0, 65535).astype(np.uint16)

        if progress_callback:
            progress_callback(num_frames, num_frames, "Fertig!")

        realized_counts = Counter()
        for traj in trajectories:
            positions = np.asarray(traj.get("positions"))
            labels = expand_labels(
                traj.get("diffusion_type", "unknown"),
                traj.get("switch_log", []),
                positions.shape[0],
            )
            label_counts = Counter(labels)
            realized_counts.update(label_counts)
            traj["realized_label_counts"] = {k: int(v) for k, v in label_counts.items()}

        total_realized_frames = sum(realized_counts.values())
        diffusion_meta = traj_gen.get_metadata()
        all_labels = set(diffusion_meta.get("diffusion_fractions", {}).keys()) | set(realized_counts.keys())
        realized_fraction_map = {}
        realized_frame_counts = {}
        for label in sorted(all_labels):
            count = int(realized_counts.get(label, 0))
            realized_frame_counts[label] = count
            realized_fraction_map[label] = (
                float(count / total_realized_frames)
                if total_realized_frames
                else 0.0
            )

        diffusion_meta["realized_fractions"] = realized_fraction_map
        diffusion_meta["realized_frame_counts"] = realized_frame_counts
        diffusion_meta["realized_total_frames"] = int(total_realized_frames)

        def _convert_for_metadata(value):
            if isinstance(value, (int, float, str, bool)) or value is None:
                return value
            if isinstance(value, dict):
                return {str(k): _convert_for_metadata(v) for k, v in value.items()}
            if isinstance(value, (list, tuple, set)):
                return [_convert_for_metadata(v) for v in value]
            return str(value)

        # Update Metadata
        self.metadata.update({
            "image_size": image_size,
            "num_spots_requested": int(num_spots),
            "num_spots_simulated": int(num_spots_effective),
            "num_spots": int(num_spots_effective),
            "num_frames": num_frames,
            "frame_rate_hz": frame_rate_hz,
            "d_initial": float(d_initial),
            "exposure_substeps": int(exposure_substeps),
            "photophysics": bool(enable_photophysics),
            "trajectories": trajectories,
            "psf": self.psf_gen.get_metadata(),
            "diffusion": diffusion_meta,
            "trajectory_options": _convert_for_metadata(traj_options),
        })

        return tiff_stack

    def generate_z_stack(self, image_size: Tuple[int, int], num_spots: int,
                        z_range_um: Tuple[float, float],
                        z_step_um: float,
                        progress_callback: Optional[Callable[[int, int, str], None]] = None) -> np.ndarray:
        """
        Generiert z-Stack f√ºr Kalibrierung (statische Spots, OPTIMIERT).
        """

        z_min, z_max = z_range_um
        z_positions = np.arange(z_min, z_max + z_step_um, z_step_um)
        n_slices = len(z_positions)

        height, width = image_size

        # Generiere statische Spot-Positionen
        spot_positions_px = []
        for _ in range(num_spots):
            x_px = np.random.uniform(0.2 * width, 0.8 * width)
            y_px = np.random.uniform(0.2 * height, 0.8 * height)
            spot_positions_px.append([x_px, y_px])

        spot_positions_px = np.array(spot_positions_px, dtype=np.float32)

        # z-Stack
        z_stack = np.zeros((n_slices, height, width), dtype=np.uint16)

        meta = self.detector.metadata or {}
        z_amp_um = float(meta.get("z_amp_um", 0.7))
        read_noise_std = float(meta.get("read_noise_std", 1.5))

        for z_idx, z_um in enumerate(z_positions):
            if progress_callback:
                progress_callback(z_idx, n_slices, f"z-Slice {z_idx+1}/{n_slices}")

            # Background
            frame = self.bg_gen.generate(image_size, use_cache=True)

            # z-abh√§ngige Intensit√§t
            amp = np.exp(- (z_um / z_amp_um) ** 2)
            spot_intensities = np.full(num_spots, self.detector.max_intensity * amp, dtype=np.float32)
            z_array = np.full(num_spots, z_um, dtype=np.float32)

            # BATCH-PSF
            psf_batch = self.psf_gen.generate_psf_batch(
                spot_positions_px, spot_intensities, z_array, image_size
            )
            frame += psf_batch

            # Noise
            frame = np.nan_to_num(frame, nan=0.0, posinf=1e6, neginf=0.0)
            frame = np.clip(frame, 0, 1e6)
            frame = np.random.poisson(frame).astype(np.float32)

            if read_noise_std > 0:
                frame += np.random.normal(0.0, read_noise_std, size=frame.shape).astype(np.float32)

            z_stack[z_idx] = np.clip(frame, 0, 65535).astype(np.uint16)

        if progress_callback:
            progress_callback(n_slices, n_slices, "z-Stack fertig!")

        # Update Metadata
        self.metadata.update({
            "image_size": image_size,
            "num_spots": num_spots,
            "z_range_um": z_range_um,
            "z_step_um": z_step_um,
            "n_slices": n_slices,
            "spot_positions": spot_positions_px.tolist()
        })

        return z_stack

    def get_metadata(self) -> Dict:
        """Gibt alle Metadata zur√ºck"""
        return self.metadata.copy()


# ============================================================================
# TIFF EXPORT
# ============================================================================

def save_tiff(filepath: str, tiff_stack: np.ndarray,
              metadata: Optional[Dict] = None) -> None:
    """Speichert TIFF-Stack mit Metadata."""

    from PIL import Image

    # Erstelle TIFF
    images = [Image.fromarray(frame) for frame in tiff_stack]

    # Speichere als Multi-Page TIFF
    images[0].save(
        filepath,
        save_all=True,
        append_images=images[1:],
        compression='tiff_deflate'
    )

    print(f"‚úÖ TIFF gespeichert: {filepath}")
    print(f"   Shape: {tiff_stack.shape}")
    print(f"   Dtype: {tiff_stack.dtype}")
    print(f"   Range: [{tiff_stack.min()}, {tiff_stack.max()}]")


# ============================================================================
# BACKWARD COMPATIBILITY - Aliase f√ºr alte Namen
# ============================================================================

# Damit alte Imports funktionieren
PSFGenerator = PSFGeneratorOptimized
BackgroundGenerator = BackgroundGeneratorOptimized
TIFFSimulator = TIFFSimulatorOptimized


# ============================================================================
# QUICK TESTING
# ============================================================================

if __name__ == "__main__":
    print("üî¨ TIFF Simulator V4.0 - OPTIMIZED Backend Test")
    print("=" * 50)

    import time

    # Test: Performance-Vergleich
    sim = TIFFSimulatorOptimized(
        detector=TDI_PRESET,
        mode="polyzeit",
        t_poly_min=60.0,
        astigmatism=False
    )

    print("\n‚ö° Performance Test: 200 Frames, 20 Spots")
    start = time.time()

    tiff = sim.generate_tiff(
        image_size=(128, 128),
        num_spots=20,
        num_frames=200,
        frame_rate_hz=20.0,
        d_initial=4.0,
        progress_callback=lambda c, t, s: print(f"  {s}") if c % 40 == 0 else None
    )

    elapsed = time.time() - start

    print(f"\n‚úÖ Test erfolgreich!")
    print(f"   TIFF Shape: {tiff.shape}")
    print(f"   Mean Intensity: {tiff.mean():.1f}")
    print(f"   Max Intensity: {tiff.max()}")
    print(f"   ‚ö° Zeit: {elapsed:.2f}s ({tiff.shape[0]/elapsed:.1f} frames/s)")
