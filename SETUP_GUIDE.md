# ðŸš€ SETUP GUIDE - TIFF Simulator V4.1 mit Random Forest

**Version 4.1 - Optimiert fÃ¼r Batch-Simulationen mit Machine Learning**

---

## ðŸ“¦ Installation (5 Minuten)

### Schritt 1: Clone Repository

```bash
git clone https://github.com/JulianLerch/Synthetic_Tiffs.git
cd Synthetic_Tiffs
```

### Schritt 2: Python Environment

**Option A: venv (Empfohlen)**
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate     # Windows
```

**Option B: conda**
```bash
conda create -n tiff-sim python=3.10
conda activate tiff-sim
```

### Schritt 3: Dependencies installieren

```bash
pip install -r requirements.txt
```

**Das installiert:**
- `numpy` - Numerische Berechnungen
- `scikit-learn` - Random Forest Klassifikator
- `joblib` - Modell-Speicherung
- `Pillow` - TIFF Export
- `matplotlib` - Visualisierung
- `tqdm` - Progress Bars
- `pyinstaller` - Desktop-App (optional)

### Schritt 4: Verifikation

```bash
python START.py
```

âœ… **Wenn die GUI startet â†’ Installation erfolgreich!**

---

## ðŸŽ¯ Quick Start: Deine erste Simulation

### Option 1: GUI (Interaktiv)

```bash
python START.py
```

1. WÃ¤hle Detektor (TDI-G0 oder Tetraspecs)
2. Setze Polymerisationszeit (z.B. 60 min)
3. Konfiguriere Image-Size (z.B. 128Ã—128)
4. Setze num_spots (z.B. 10)
5. Setze num_frames (z.B. 100)
6. Klicke "SIMULATION STARTEN"

â†’ **Output:** `output_dir/simulation.tif` + Metadata

### Option 2: Python Script (Schnell)

```python
from tiff_simulator_v3 import TDI_PRESET, TIFFSimulator, save_tiff

# Simulator erstellen
sim = TIFFSimulator(
    detector=TDI_PRESET,
    mode="polyzeit",
    t_poly_min=60.0
)

# TIFF generieren
tiff_stack = sim.generate_tiff(
    image_size=(128, 128),
    num_spots=10,
    num_frames=100,
    frame_rate_hz=20.0
)

# Speichern
save_tiff("my_simulation.tif", tiff_stack)
print("âœ… TIFF erstellt!")
```

### Option 3: Command-Line Batch (Production)

```bash
# Quick Test (3 TIFFs, ~2 min)
python batch_simulator.py --preset quick --output ./test_output

# Thesis Full (63 TIFFs, ~45 min)
python batch_simulator.py --preset thesis --output ./thesis_data

# MIT Random Forest Training!
python batch_simulator.py --preset thesis --train-rf --output ./thesis_rf_data
```

---

## ðŸŒ² Random Forest Training (Das neue Feature!)

### Was macht das RF-Modul?

**Automatisches Training eines Random Forest Klassifikators** wÃ¤hrend der Batch-Simulation, der zwischen 4 Diffusionstypen unterscheidet:

- **Normal Diffusion** (Brownian Motion)
- **Subdiffusion** (Anomalous, Î± < 1)
- **Confined Diffusion** (In Poren gefangen)
- **Superdiffusion** (Konvektion, Î± > 1)

### Basis-Nutzung

```bash
python batch_simulator.py \
  --preset thesis \
  --train-rf \
  --output ./my_rf_data
```

**Das erstellt:**
```
my_rf_data/
â”œâ”€â”€ tdi-g0_t000min_rep1.tif       # Simulationen
â”œâ”€â”€ tdi-g0_t010min_rep1.tif
â”œâ”€â”€ ...
â”œâ”€â”€ random_forest_diffusion.joblib  # â† Trainiertes Modell!
â”œâ”€â”€ rf_training_features.csv        # â† Feature-Matrix
â”œâ”€â”€ rf_training_summary.json        # â† Metriken & Confusion Matrix
â””â”€â”€ batch_statistics.json
```

### Advanced RF-Konfiguration

```bash
python batch_simulator.py \
  --preset thesis \
  --train-rf \
  --rf-window 48 \           # Sliding-Window GrÃ¶ÃŸe (Frames)
  --rf-step 32 \             # Schrittweite (weniger Overlap = weniger Leakage)
  --rf-estimators 2048 \     # Anzahl BÃ¤ume
  --rf-max-depth 20 \        # Max Tiefe (Regularisierung)
  --rf-min-leaf 5 \          # Min Samples pro Blatt (Regularisierung)
  --rf-min-split 10 \        # Min Samples fÃ¼r Split (Regularisierung)
  --output ./optimized_rf
```

### RF-Ergebnisse analysieren

```python
import json
from joblib import load

# 1. Lade Modell
model_data = load("./my_rf_data/random_forest_diffusion.joblib")
rf_model = model_data["model"]
feature_names = model_data["feature_names"]

# 2. Lade Metriken
with open("./my_rf_data/rf_training_summary.json") as f:
    summary = json.load(f)

print(f"Training Accuracy: {summary['training_accuracy']:.4f}")
print(f"OOB Score: {summary['oob_score']:.4f}")
print(f"Samples: {summary['samples']}")
print(f"\nKlassen-Verteilung:")
for label, count in summary['labels'].items():
    print(f"  {label}: {count}")

# 3. Feature Importance
import numpy as np
import matplotlib.pyplot as plt

importances = summary['feature_importances']
indices = np.argsort(importances)[::-1][:10]  # Top 10

plt.figure(figsize=(12, 6))
plt.bar(range(10), [importances[i] for i in indices])
plt.xticks(range(10), [feature_names[i] for i in indices], rotation=45)
plt.title("Top 10 Feature Importances")
plt.tight_layout()
plt.savefig("feature_importance.png")
print("âœ… Plot gespeichert: feature_importance.png")
```

---

## ðŸ“Š Batch-Modi Ãœbersicht

### Quick Test
```bash
python batch_simulator.py --preset quick
```
- **3 TIFFs** (t=30, 60, 90 min)
- 64Ã—64 px, 5 Spots, 50 Frames
- **Dauer:** ~2 Minuten
- **Zweck:** Testen, ob alles funktioniert

### Thesis Full
```bash
python batch_simulator.py --preset thesis
```
- **63 TIFFs** (7 Zeiten Ã— 3 Repeats = 21, + Detektor-Vergleich, + 3D, + z-Stacks)
- 128Ã—128 px, 15 Spots, 200 Frames
- **Dauer:** ~45 Minuten
- **Zweck:** VollstÃ¤ndige Parameterstudie fÃ¼r Masterthesis

### Publication Quality
```bash
python batch_simulator.py --preset publication
```
- **25 TIFFs** (5 Zeiten Ã— 5 Repeats)
- 256Ã—256 px, 50 Spots, 500 Frames
- **Dauer:** ~2-3 Stunden
- **Zweck:** High-Quality Daten fÃ¼r Paper

---

## ðŸ”¬ Custom Batch-Konfiguration

### Python API

```python
from batch_simulator import BatchSimulator
from tiff_simulator_v3 import TDI_PRESET

# Erstelle Batch mit RF-Training
batch = BatchSimulator(
    output_dir="./custom_batch",
    enable_rf=True,
    rf_config={
        'window_size': 48,
        'step_size': 32,
        'n_estimators': 2048,
        'max_depth': 20,
        'min_samples_leaf': 5,
        'min_samples_split': 10
    }
)

# FÃ¼ge Polymerisationszeit-Serie hinzu
batch.add_polyzeit_series(
    times=[0, 10, 30, 60, 90, 120, 180],
    detector=TDI_PRESET,
    repeats=3,
    image_size=(128, 128),
    num_spots=15,
    num_frames=200,
    frame_rate_hz=20.0
)

# Run!
stats = batch.run()

# Check RF-Ergebnisse
if stats['rf']['trained']:
    print(f"âœ… RF Training erfolgreich!")
    print(f"   Samples: {stats['rf']['samples']}")
    print(f"   Accuracy: {stats['rf']['training_accuracy']:.4f}")
    print(f"   OOB: {stats['rf']['oob_score']:.4f}")
    print(f"   Modell: {stats['rf']['model_path']}")
```

### Command-Line Custom Times

```bash
python batch_simulator.py \
  --times "0,5,10,20,30,45,60,90,120,180" \
  --repeats 5 \
  --detector tdi \
  --train-rf \
  --output ./custom_times
```

---

## ðŸ› ï¸ Troubleshooting

### Problem: "Import Error: sklearn not found"

**LÃ¶sung:**
```bash
pip install scikit-learn>=1.2.0
```

### Problem: "tkinter not found" (Linux)

**LÃ¶sung:**
```bash
# Ubuntu/Debian
sudo apt-get install python3-tk

# Fedora/RHEL
sudo dnf install python3-tkinter
```

### Problem: RF Training dauert zu lange

**Ursache:** Zu viele Windows pro Trajektorie

**LÃ¶sung:**
```bash
# Reduziere Window-Dichte
python batch_simulator.py \
  --preset thesis \
  --train-rf \
  --rf-step 48  # GrÃ¶ÃŸerer Step = weniger Windows
```

### Problem: Training Accuracy = 100% (Overfitting!)

**LÃ¶sung:** Mehr Regularisierung
```bash
python batch_simulator.py \
  --preset thesis \
  --train-rf \
  --rf-max-depth 15 \      # Kleinere Tiefe
  --rf-min-leaf 10 \       # GrÃ¶ÃŸere Leaf-Size
  --rf-min-split 20        # GrÃ¶ÃŸere Split-Size
```

---

## ðŸ“ˆ Erwartete Performance

### Typische RF-Metriken (nach Optimierung)

**Bei Thesis-Batch mit RF:**
```
Samples: ~5000-8000 Windows
Training Accuracy: 88-92%
OOB Score: 86-90%
Test Accuracy (auf echten Daten): 82-88%

Per-Class:
- Normal: Precision ~95%, Recall ~93%
- Subdiffusion: Precision ~88%, Recall ~85%
- Confined: Precision ~82%, Recall ~78%
- Superdiffusion: Precision ~90%, Recall ~88%
```

### Feature Importance (Top 5)

Erwarte folgende Features als wichtigste:

1. **msd_loglog_slope** (~15-20%) - Der MSD-Exponent Î± ist DAS Kriterium!
2. **straightness** (~8-12%) - Trennt Confined vs. Super gut
3. **confinement_radius** (~6-10%) - Wichtig fÃ¼r Confined
4. **mean_step_xy** (~5-8%) - Basic Mobility
5. **directional_persistence** (~4-7%) - Wichtig fÃ¼r Super

---

## ðŸŽ“ Wissenschaftliche HintergrÃ¼nde

### Diffusionstypen

| Typ | Physik | MSD(t) | Beispiele |
|-----|--------|--------|-----------|
| Normal | Brownian Motion | 6Dt | Freie Diffusion in Wasser |
| Subdiffusion | Anomalous (Î±<1) | Dt^Î± | Viskoelastische Hydrogele, Molecular Crowding |
| Confined | Harmonic Potential | D(1-e^(-t/Ï„)) | Poren, KÃ¤fige, Compartments |
| Superdiffusion | Levy Flight (Î±>1) | Dt^Î± | Konvektion, Aktiver Transport |

### Polymerisationsmodell

```
D(t) = Dâ‚€ Â· exp(-t / Ï„)

Ï„ â‰ˆ 32 min (radikalische Polymerisation)
Dâ‚€ = 4.0 ÂµmÂ²/s (Liquid)
D_final â‰ˆ 0.04 ÂµmÂ²/s (Cross-linked Gel)
```

**Referenzen:**
- Metzler & Klafter (2000): "The random walk's guide to anomalous diffusion"
- Anseth et al. (1996): "Photopolymerization kinetics"
- Bryant & Anseth (2002): "Hydrogel properties during gelation"

---

## ðŸš€ Next Steps

### 1. Teste das System

```bash
# Quick Test
python batch_simulator.py --preset quick --train-rf --output ./test
```

### 2. Full Thesis Run

```bash
# Mit RF-Training (~45-60 min)
python batch_simulator.py --preset thesis --train-rf --output ./thesis_data
```

### 3. Analysiere Ergebnisse

```python
# Siehe "RF-Ergebnisse analysieren" oben
```

### 4. Validiere auf echten Daten

```python
from joblib import load
import numpy as np

# Lade trainiertes Modell
model_data = load("./thesis_data/random_forest_diffusion.joblib")
rf_model = model_data["model"]

# Deine echten Trajektorien (aus Experimenten)
# ... Feature-Extraktion mit gleichen 27 Features ...
# real_features = extract_features(real_trajectories)

# Predict
predictions = rf_model.predict(real_features)
probabilities = rf_model.predict_proba(real_features)

print(f"Predicted classes: {predictions}")
print(f"Probabilities: {probabilities}")
```

---

## ðŸ’¡ Tips & Tricks

### 1. Parallelisierung nutzen

Random Forest nutzt automatisch alle CPU-Cores:
```python
# In rf_trainer.py:
n_jobs=-1  # Nutzt alle verfÃ¼gbaren Cores
```

### 2. Memory-Effizienz

Bei sehr groÃŸen Batches (>100 TIFFs):
```bash
python batch_simulator.py \
  --preset thesis \
  --train-rf \
  --rf-max-windows-per-class 50000 \  # Limitiert Samples
  --rf-max-windows-per-track 300       # Limitiert Windows pro Trajektorie
```

### 3. Reproduzierbarkeit

FÃ¼r exakt reproduzierbare Ergebnisse:
```python
# In rf_trainer.py:
random_state=42  # Fester Seed
```

Und in `batch_simulator.py`:
```python
np.random.seed(42)
```

---

## ðŸ“ž Support

Bei Fragen oder Problemen:
1. Siehe [BUILD_TROUBLESHOOTING.md](BUILD_TROUBLESHOOTING.md)
2. Siehe [BATCH_MODE_GUIDE.md](BATCH_MODE_GUIDE.md)
3. Ã–ffne ein Issue auf GitHub

---

## âœ… Checkliste: Bereit fÃ¼r Production

- [ ] `pip install -r requirements.txt` erfolgreich
- [ ] `python START.py` startet GUI
- [ ] Quick Test lÃ¤uft durch: `python batch_simulator.py --preset quick`
- [ ] RF-Training funktioniert: `--train-rf` Flag
- [ ] Modell-Output existiert: `random_forest_diffusion.joblib`
- [ ] Metriken sehen plausibel aus: OOB Score 85-90%
- [ ] Feature Importance zeigt `msd_loglog_slope` als Top-Feature

**Wenn alle Checkboxen âœ… â†’ Ready to go! ðŸš€**

---

**Version:** 4.1
**Datum:** November 2025
**Optimierungen:** Reduzierte Switching-Rate, RF Regularisierung, Superdiffusion-Training
**Autor:** Julian Lerch / Claude AI Assistant
